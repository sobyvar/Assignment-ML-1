{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-1 What are the three stages to build the hypotheses or model in machine learning?\n",
    "# 3 stages to build the model in machine larning are\n",
    "# a) Data Preparations\n",
    "# b) Training set generation\n",
    "# c) Algorithm Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-2 What is the standard approach to supervised learning?\n",
    "# Supervised learning algorithms are trained using labeled examples, The learning algorithm receives a set of inputs along with the corresponding correct outputs, and the\n",
    "# algorithm learns by comparing its actual output with correct outputs to find errors. It then modifies the model accordingly.\n",
    "# Through methods like classification, regression, prediction and gradient boosting, supervised\n",
    "# learning uses patterns to predict the values of the label on additional unlabeled data.\n",
    "# Supervised algorithms can further devided into following:\n",
    "# a) Classification. When the data are being used to predict a category, supervised learning is also\n",
    "# called classification.\n",
    "# b) Regression. When a value is being predicted, as with stock prices, supervised learning is called\n",
    "# regression.\n",
    "# c) Anomaly detection. Sometimes the goal is to identify data points that are simply unusual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-3  What is Training set and Test set?\n",
    "# Training Set- A training set is a dataset used to train a model. In training the model, specific features\n",
    "# are picked out from the training set. These features are then incorporated into the model. Thereby, if the\n",
    "# training set is labeled correctly, the model should be able to learn something from these features.\n",
    "#\n",
    "# Test set- The test set is a dataset used to measure how well the model performs at making predictions on that test set.\n",
    "# If the prediction scores for the test set are unreasonable, we’ll need to make some adjustments to our model\n",
    "# and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 What is the general principle of an ensemble method and what is bagging and\n",
    "# boosting in ensemble method?\n",
    "# This methods combine several decision trees classifiers to produce better predictive performance than a single decision tree classifier. \n",
    "# The main principle behind the ensemble model is that a group of weak learners come together to form a strong learner,\n",
    "# thus increasing the accuracy of the model.When we try to predict the target variable using any machine learning technique, \n",
    "# the main causes of difference in actual and predicted values are noise, variance, and bias.\n",
    "# Ensemble helps to reduce these factors (except noise, which is irreducible error).\n",
    "# Using techniques like Bagging and Boosting helps to decrease the variance and increased the robustness of the model.\n",
    "#BAGGING\n",
    "#Bootstrap Aggregation (or Bagging for short), is a simple and very powerful ensemble method. \n",
    "# Bagging is the application of the Bootstrap procedure to a high-variance machine learning algorithm, typically decision trees.\n",
    "#\n",
    "#Suppose there are N observations and M features. A sample from observation is selected randomly with replacement(Bootstrapping).\n",
    "#A subset of features are selected to create a model with sample of observations and subset of features.\n",
    "#Feature from the subset is selected which gives the best split on the training data.\n",
    "#This is repeated to create many models and every model is trained in parallel\n",
    "#Prediction is given based on the aggregation of predictions from all the models\n",
    "#BOOSTING\n",
    "#Boosting refers to a group of algorithms that utilize weighted averages to make weak learners into stronger learners. \n",
    "#Unlike bagging that had each model run independently and then aggregate the outputs at the end without preference to any model. \n",
    "#Boosting is all about “teamwork”. Each model that runs, dictates what features the next model will focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-5 How can you avoid overfitting ?\n",
    "# 1) By choosing the alogorithm accurately\n",
    "# 2) By avoding the model to  learns everything from  the training data \n",
    "# 3) This problem can be addressed by pruning a tree after it has learned in\n",
    "#    order to remove some of the detail it has picked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
